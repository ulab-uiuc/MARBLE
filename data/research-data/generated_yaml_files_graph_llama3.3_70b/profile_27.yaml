agents:
- agent_id: agent1
  profile: 'I am a researcher deeply engaged in the intersection of photonics, topological
    materials, and machine learning. My work explores the intricate relationships
    between topology and nonreciprocity in photonic systems, where I investigate how
    topological properties like Chern numbers and Berry phases influence wave propagation
    and edge states. I have developed innovative models, such as the Dilated Neighborhood
    Attention Transformer (DiNAT), which enhances the performance of vision transformers
    by efficiently capturing global context while maintaining computational efficiency.


    My research also delves into the dynamics of light-matter interactions, particularly
    in nonreciprocal environments, where I analyze phenomena like the Casimir-Polder
    force and the behavior of entangled qubits near photonic topological insulators.
    I am particularly interested in how these systems can be harnessed for robust
    wave propagation and quantum information processing.


    In addition to theoretical advancements, I have contributed to practical applications,
    such as developing efficient clustering methods for high-dimensional data and
    proposing novel quantum photonic gates. My goal is to bridge fundamental physics
    with practical technologies, paving the way for new applications in quantum optics
    and advanced machine learning frameworks. Through my work, I aim to inspire further
    exploration in these exciting fields and contribute to the development of next-generation
    photonic devices.'
  type: BaseAgent
- agent_id: agent2
  profile: "As a researcher deeply engaged in the fields of machine learning (ML)\
    \ and deep learning (DL), I am passionate about addressing the challenges that\
    \ arise from the rapid pace of innovation in these areas. My recent work focuses\
    \ on creating standardized specifications that enhance the reproducibility and\
    \ comparability of DL tasks. I developed DLSpec, a comprehensive framework that\
    \ is model-, dataset-, software-, and hardware-agnostic, allowing researchers\
    \ to specify and run a wide range of DL tasks seamlessly. \n\nRecognizing the\
    \ complexities involved in evaluating ML/DL models, I also introduced MLModelScope,\
    \ which tackles common pitfalls in model evaluation. This specification not only\
    \ streamlines the evaluation process but also ensures that experiments can be\
    \ replicated accurately, thereby facilitating the rapid adoption of new innovations\
    \ in the field. My goal is to create tools and frameworks that empower researchers\
    \ and practitioners to navigate the evolving landscape of ML and DL with greater\
    \ ease and confidence."
  type: BaseAgent
- agent_id: agent3
  profile: 'I am a researcher deeply engaged in the field of computer vision, with
    a particular focus on advancing techniques for 3D point cloud understanding, human-object
    interaction detection, and multimodal learning. My work spans a variety of innovative
    architectures and methodologies, including the development of the Dilated Neighborhood
    Attention Transformer (DiNAT) and the Matting Anything Model (MAM), which enhance
    performance in object detection and image matting tasks, respectively.


    I have also explored the integration of vision-language models, proposing the
    Versatile vision enCoders (VCoder) to improve object perception in multimodal
    large language models. My research on efficient image generation led to the creation
    of StyleNAT, a transformer-based framework that achieves state-of-the-art results
    in high-quality image generation while maintaining efficiency.


    In addition to these contributions, I have tackled challenges in video instance
    segmentation with the Mask Selection Network (MSN) and addressed the unlearning
    problem in generative models through my Forget-Me-Not framework. My work emphasizes
    the importance of robustness and adaptability in deep learning systems, particularly
    in the face of noisy data and dynamic environments.


    I am committed to open-sourcing my code and models to foster collaboration and
    innovation within the research community. My goal is to push the boundaries of
    what is possible in computer vision and machine learning, ultimately contributing
    to practical applications in areas such as autonomous driving and robotics.'
  type: BaseAgent
coordinate_mode: graph
engine_planner:
  initial_progress: Starting the collaborative research idea generation based on the
    provided Introduction.
environment:
  max_iterations: 5
  name: Research Collaboration Environment
  type: Research
llm: together_ai/meta-llama/Meta-Llama-3.3-70B-Instruct-Turbo
memory:
  type: SharedMemory
metrics:
  diversity_of_perspectives: true
  engagement_level: true
  evaluate_llm: gpt-4o-mini
  relevance: true
output:
  file_path: result/discussion_output_llama3.3_70b.jsonl
  format: jsonl
relationships:
- - agent1
  - agent2
  - collaborate with
- - agent1
  - agent3
  - collaborate with
- - agent2
  - agent3
  - collaborate with
task:
  content: "\n            Dear Research Team,\n\n            You are collaborating\
    \ to generate a new research idea based on the following Introduction:\n\n   \
    \         **Introduction**\n\n               1 Introduction  Inarguably among\
    \ the most highly utilized and influential primitives in modern deep learning,\
    \ attention has long been cited for its complexity and memory footprint, especially\
    \ when the query and context sets are identical (self attention). For years since\
    \ its adoption in deep learning [20], the most common implementation of attention\
    \ was through two batched GEMM (General Matrix-Matrix Multiplication) operations,\
    \ sometimes referred to as “BMM-style” attention. This implementation stores attention\
    \ weights to global memory, which can become a bottleneck in both speed and memory\
    \ footprint. As the number of possible attention weights grow, the problem gets\
    \ bounded by global memory bandwidth, as well as the amount of global memory required.\
    \   Over the past few years, some works proposed attention implementations in\
    \ which attention weights are not stored to global memory, but instead kept in\
    \ on-chip memory (shared memory or register file) [16, 5], which are then directly\
    \ applied to corresponding values, writing the resulting attention outputs to\
    \ global memory. These implementations, known as fused or memory-efficient attention,\
    \ reduce the number of global memory accesses in addition to global memory usage.\
    \ Thanks to the first open-source implementation, Flash Attention [5], these fused\
    \ attention kernels have started replacing the standard BMM-style implementations\
    \ in many deep learning frameworks and inference engines such as PyTorch [14].\
    \   Orthogonal to these efforts, many have sought to address the quadratic complexity\
    \ in self attention, which is the more predominantly used operation in vision\
    \ models. Neighborhood attention [8] is one such method in which each query token\
    \ is restricted to only interact with its nearest neighboring context tokens.\
    \ In most cases, this pattern creates a sliding window pattern, which in deep\
    \ learning can also be seen in the convolution operator. This restriction can\
    \ similarly be parameterized by a window size and dilation factor, and reduces\
    \ the quadratic complexity of self attention down to a linear complexity. This\
    \ reduction is however very difficult to implement at the tensor library or deep\
    \ learning framework level. Tensor views can represent sliding window attention [17],\
    \ but not the neighborhood attention pattern. In addition, GEMM operators do not\
    \ typically support taking in the sliding window views in higher-rank spaces (2-D\
    \ and 3-D) without explicit copying, which in practice undoes the theoretical\
    \ efficiency gain from the reduced attention complexity. As a result, neighborhood\
    \ attention was proposed along with an extension carrying naive CUDA kernels [8]\
    \ implementing the two BMM operators. While those kernels can provide competitive\
    \ FP32 performance, and in some cases even FP16/BF16 performance, they fall short\
    \ of being generally adoptable in larger scale experiments. In addition, fused\
    \ attention kernels such as Flash Attention effectively eliminate the \U0001D4AA\
    ⁢(n2)\U0001D4AAsuperscript\U0001D45B2\\mathcal{O}(n^{2})caligraphic_O ( italic_n\
    \ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) memory footprint in self attention,\
    \ while also reducing latency significantly [5], making subquadratic attention\
    \ patterns that are only possible to implement in “BMM-style” less feasible in\
    \ practice.   In this work, we present two new classes of neighborhood attention\
    \ kernels: GEMM-based BMM-style kernels (GEMM NA), and fused kernels (Fused NA),\
    \ which are aimed at providing significantly improved infrastructure for neighborhood\
    \ attention. We first show that neighborhood attention, and by extension sliding\
    \ window attention, both of which are GEMV (General Matrix-Vector Multiplication)\
    \ problems, can be expressed as GEMM problems with space-aware tiling and gather/scatter\
    \ fusion. This would allow implementing such attention patterns with GEMMs, which\
    \ in turn can benefit greatly from the underlying efficiency of GEMM\n\n     \
    \       **Your Task**\n\n            1. **Literature Review**: Analyze the Introduction\
    \ provided and conduct a brief literature review to understand the current state\
    \ of research in this area.\n\n            2. **Brainstorming**: Collaboratively\
    \ brainstorm potential research ideas that build upon or address gaps in the Introduction.\n\
    \n            3. **Summarization**: Summarize your collective ideas.\n\n     \
    \       4. **Formulate a New Research Idea**: Develop a new research proposal\
    \ in the format of the '5q', defined below:\n\n               **Here is a high-level\
    \ summarized insight of a research field Machine Learning.**\n\n             \
    \  **Here are the five core questions:**\n\n               **[Question 1] - What\
    \ is the problem?**\n\n               Formulate the specific research question\
    \ you aim to address. Only output one question and do not include any more information.\n\
    \n               **[Question 2] - Why is it interesting and important?**\n\n \
    \              Explain the broader implications of solving this problem for the\
    \ research community.\n               Discuss how such a paper will affect future\
    \ research.\n               Discuss how addressing this question could advance\
    \ knowledge or lead to practical applications.\n\n               **[Question 3]\
    \ - Why is it hard?**\n\n               Discuss the challenges and complexities\
    \ involved in solving this problem.\n               Explain why naive or straightforward\
    \ approaches may fail.\n               Identify any technical, theoretical, or\
    \ practical obstacles that need to be overcome. MAKE IT CLEAR.\n\n           \
    \    **[Question 4] - Why hasn't it been solved before?**\n\n               Identify\
    \ gaps or limitations in previous research or existing solutions.\n          \
    \     Discuss any barriers that have prevented this problem from being solved\
    \ until now.\n               Explain how your approach differs from or improves\
    \ upon prior work. MAKE IT CLEAR.\n\n               **[Question 5] - What are\
    \ the key components of my approach and results?**\n\n               Outline your\
    \ proposed methodology in detail, including the method, dataset, and metrics that\
    \ you plan to use.\n               Describe the expected outcomes. MAKE IT CLEAR.\n\
    \n            Please work together to produce the '5q' for your proposed research\
    \ idea.\n\n            Good luck!\n            "
  output_format: "You should answer the task in the following format:\n          \
    \      **[Question 1] - What is the problem?**\n\n                Formulate the\
    \ specific research question you aim to address. Only output one question and\
    \ do not include any more information.\n\n                **[Question 2] - Why\
    \ is it interesting and important?**\n\n                Explain the broader implications\
    \ of solving this problem for the research community.\n                Discuss\
    \ how such a paper will affect future research.\n                Discuss how addressing\
    \ this question could advance knowledge or lead to practical applications.\n\n\
    \                **[Question 3] - Why is it hard?**\n\n                Discuss\
    \ the challenges and complexities involved in solving this problem.\n        \
    \        Explain why naive or straightforward approaches may fail.\n         \
    \       Identify any technical, theoretical, or practical obstacles that need\
    \ to be overcome. MAKE IT CLEAR.\n\n                **[Question 4] - Why hasn't\
    \ it been solved before?**\n\n                Identify gaps or limitations in\
    \ previous research or existing solutions.\n                Discuss any barriers\
    \ that have prevented this problem from being solved until now.\n            \
    \    Explain how your approach differs from or improves upon prior work. MAKE\
    \ IT CLEAR.\n\n                **[Question 5] - What are the key components of\
    \ my approach and results?**\n\n                Outline your proposed methodology\
    \ in detail, including the method, dataset, and metrics that you plan to use.\n\
    \                Describe the expected outcomes. MAKE IT CLEAR."
